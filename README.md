## Installation  
To install the project dependencies, follow these steps:  

1. Navigate to the project directory:  
   `cd "path to project"`  

2. Install the dependencies:  
   `pip install -e ".[dev]"`  

## Running Tests  
To execute all tests, run the following command:  
`pytest`  

## Running the Application  
To start the application, navigate to the `src` directory and execute:  
`python main.py`  

The project will start and output the results.  

# Alzheimer's Disease Risk Prediction

Alzheimer's disease poses a global medical and social challenge, impacting millions worldwide. Researching the factors influencing its onset and developing early prediction tools could improve diagnostic processes. This project aims to investigate the main factors affecting Alzheimer's disease and develop a model to predict the risk of its onset using clinical and brain-related data.

## Dataset Overview

The dataset consists of an Excel table with 10 columns representing various variables. The study includes 150 participants aged 60–96, examined multiple times over the years. Each participant underwent at least two imaging tests a year or more apart, with a total of 373 scans. During each session, participants completed 3–4 T1-weighted MRI scans. All participants are right-handed, including both men and women.

### Participant Information:
- 72 participants showed no signs of dementia throughout the study.
- 64 participants were diagnosed with dementia from their first visit, 51 of whom had mild-to-moderate Alzheimer's.
- 14 participants, initially without dementia, were later diagnosed in follow-up visits.

## Research Question

**How do anatomical factors (eTIV, nWBV, ASF) influence the risk of developing Alzheimer's disease, and can they be used as early markers for identifying disease risk?**

## Data Preparation

We took a raw dataset containing variables for patients with and without dementia. We removed irrelevant variables and focused on the following key factors for our research question:
- **eTIV** (Estimated Total Intracranial Volume)
- **nWBV** (Normalized Whole Brain Volume)
- **ASF** (Atlas Scaling Factor)

### Data Analysis Code Files:

- **DATA_ANALYSIS_PY**: This file verifies that all input values are numeric, checks statistical variables, and saves results across different columns.
  
- **DATA_ANALYSIS_TEST**: This test ensures that the functions comparing groups in the data perform correctly and carry out statistical calculations accurately, which is essential for reliable analysis.

- **DATA_CLEANING_PY**: Cleans the provided DataFrame by:
  - Checking for required columns and raising an error if any are missing.
  - Dropping rows with missing values in the required columns.
  - Filling missing values in numeric columns with the column's mean.
  - Returning a DataFrame containing only the relevant columns.

- **DATA_CLEANING_TEST**: Tests the correctness of the `clean_data` function, ensuring it handles missing columns and missing values properly, and returns only the required columns.

- **DATA_VISUALIZATION_PY**: Generates and saves various visual plots for specific metrics across different groups in the DataFrame. This is crucial for visually illustrating and comparing the data distribution.

- **DATA_VISUALIZATION_TEST**: We did not see the need for a test file for the visualization code. As long as we verified mathematical values and cleaned error-prone options in previous tests, there's no reason for errors in visualization.

- **MAIN_PY**: This file organizes the entire data analysis workflow. It:
  - Loads the data from a CSV file in the data folder.
  - Calls the `clean_data` function from `data_cleaning.py` to clean the data and saves the cleaned dataset.
  - Runs the `main_analysis` function from `data_analysis.py` for statistical analysis.
  - Uses the `visualize_group_data` function from `data_visualization.py` to generate and save visualizations.
  
  The script runs the `main()` function only if executed directly, ensuring it doesn't run when imported as a module.

- **MAIN_PY_TEST**: This file tests that the main function produces the expected outputs, describing the expected files and checking if each file exists.

## Folder Structure

The project directory is organized as follows:
- **data**: Contains the raw dataset and cleaned data files.
- **src**: Contains the Python source code files (`data_cleaning.py`, `data_analysis.py`, `data_visualization.py`, `main.py`).
- **tests**: Contains test files to ensure the correctness of the code (e.g., `data_cleaning_test.py`, `data_analysis_test.py`).
- **plots**: Stores the visual plots generated by the `DATA_VISUALIZATION_PY` script.
- **analysis**: Stores the results from statistical analysis performed by the `DATA_ANALYSIS_PY` script.
